# -*- coding: utf-8 -*-
"""370_Mod_10_Supervised_Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11obSdVoPb-LZZU9LY6zKBkTauz7pNVpc

Desciption:
Created by: Jalyn Buthman
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

#modify pandas display options to show all columns and not wrap
pd.set_option('display.max_columns', None)
pd.set_option('display.expand_frame_repr', False)

#read in the data
news = pd.read_csv("/content/OnlineNewsPopularity.csv")
print(news.head())
print()

#target variable for this dataset: shares
#k Nearest Neighbor, try to identify articles that have a similar sentiment and see how many shares it has
#start by defining k (the number of neighbors) and target value
###set a test value for newtech
k = 15
newsentiment = 0.5
newtech = 0
newweekend = 1

#convert all sentiments and shares to lists
###define newtech variable
allsentiment = news[' global_sentiment_polarity'].tolist()
allshares = news[' shares'].tolist()
alltech = news[' data_channel_is_tech'].tolist()
allweekend = news[' is_weekend'].tolist()


#create the x and y variable
###update the reshape numbers to have the second be 2, for two columns
x= np.array([allsentiment, alltech, allweekend]).reshape(-1, 3)
y = np.array(allshares)
predictor_array = np.array([newsentiment, newtech, newweekend]).reshape(1, -1)

#create a regressor and fit it to our data
from sklearn.neighbors import KNeighborsRegressor
knnregressor = KNeighborsRegressor(n_neighbors = k)
knnregressor.fit (x, y)

#print the prediction for shares for the sentiment score
###add in newtech variable
print('Mean shares of the 15 nearest neighbors: ')
print(knnregressor.predict(predictor_array))
print()
#the 15 articles that had a have a sentiment closest to 0.5 had a sentiment score of 7,344
#compare this model to other models to see how accurate this prediction is

#decision tree
#max depth is how complicated you want the analysis to be
from sklearn.tree import DecisionTreeRegressor
dtregressor = DecisionTreeRegressor (max_depth = 3)
dtregressor.fit (x, y)
print('My decision tree prediction of number of shares: ')
print(dtregressor.predict(predictor_array))
print()
#the decision tree outcome is much lower than the k nearest neighbor model


#random forest
#may take a lot of computing power
from sklearn.ensemble import RandomForestRegressor
rfregressor = RandomForestRegressor()
rfregressor.fit(x, y)
print('Random forest prediction of number of shares: ')
print(rfregressor.predict(predictor_array))
print()
#random forest's prediction is in between the decision tree and k nearest neighbor values


#neural network
from sklearn.neural_network import MLPRegressor
nnregressor = MLPRegressor()
nnregressor.fit(x, y)
print('Neural network prediction of number of shares: ')
print(nnregressor.predict(predictor_array))
print()


#accuracy testing
#create a train, test data with 75/25 split, used to train data and test accuracy
from sklearn.model_selection import train_test_split
trainingx, testx, trainingy, testy = train_test_split(x, y, random_state = 1)


#use each technique on the train/test data to see which is the most accurate/smallest error

#K nearest neighbor
knnregressor = KNeighborsRegressor(n_neighbors = 15)
knnregressor.fit (trainingx, trainingy)
predicted = knnregressor.predict(testx)
predictionerror = abs(predicted - testy)
print('Nearest neighbor prediction score: ')
print(np.mean(predictionerror))
print()

#decision trees
dtregressor = DecisionTreeRegressor(max_depth = 3)
dtregressor.fit (trainingx, trainingy)
predicted = dtregressor.predict(testx)
predictionerror = abs(predicted - testy)
print('Decision Tree prediction score: ')
print(np.mean(predictionerror))
print()

#random forest
rfregressor = RandomForestRegressor(random_state = 1)
rfregressor.fit (trainingx, trainingy)
predicted = rfregressor.predict(testx)
predictionerror = abs(predicted - testy)
print('Random forest prediction score: ')
print(np.mean(predictionerror))
print()

#neural network
nnregressor = MLPRegressor()
nnregressor.fit (trainingx, trainingy)
predicted = rfregressor.predict(testx)
predictionerror = abs(predicted - testy)
print('Neural network prediction score: ')
print(np.mean(predictionerror))
print()

#check which supervised learning technique has the least amount of errors to choose which model to use for predictions