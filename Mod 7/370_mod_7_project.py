# -*- coding: utf-8 -*-
"""370_Mod_7_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RD5GrhQDyBTCQV2LvzQA15bGt3VjWN0p

Binary Classification - Flight Delays

Jalyn Buthman
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix

#read in the dataset
flights = pd.read_csv("/content/airlines_subset.csv")

print(flights.describe())
print()
print(f'Within this dataset 0 means that the flight was not delayed and 1 means that the flight was delayed.')
print(f'The mean value for "delayed" is 0.46, which means that almost half of the flights (46%) in the dataset were delayed.')
print()

#create a model with outcome variable 'delayed' and independant variable 'flight_length'
model = LogisticRegression(solver= 'liblinear', random_state = 0)
x = flights ['flight_length'].values.reshape(-1, 1)
y = flights ['delayed'].values.reshape(-1, 1)
model.fit(x, y)

#add the predicted probabilities for delayed flights as a new column in the dataframe
flights['logistic_regression'] = model.predict_proba(x)[:,1]

#print the 10 largest predicted probabilities for delayed flights
print('The 10 highest predicted probabilities of a flight being delayed:')
print(flights.nlargest(10, 'logistic_regression'))
print()
print(f'The 10 flights with the highest probabilities of being delayed according to our model all had a .650 logistic regression score.')
print(f'We can also see here that the model is not perfect at predicting delayed flights, as it included 2 flights that we know were not delayed.')
print()

#create and print a confussion matrix
the_median = flights['logistic_regression'].median()
#print(the_median)
prediction = list(1 * flights['logistic_regression'] > the_median)
actual = list(flights['delayed'])
print('Confusion Matrix:')
print('[True positive   False positives]')
print ('[False negatives True negatives]')
print(confusion_matrix(prediction, actual))
print()

#save the confusion matrix
conf_mat = confusion_matrix(prediction, actual)

#calculate the precision
precision = conf_mat[0][0] / (conf_mat[0][0] + conf_mat[0][1])
print(f'Precision: {precision}')
print()

#calculate the recall
recall = conf_mat[0][0] / (conf_mat[0][0] + conf_mat[1][0])
print(f'Recall: {recall}')
print()
print(f'')

print(f'The precision and recall scores for this model could both be better, as they are closer to 0.5 than to 1.0. While they are not bad accuracy scores, there is room for improvement.')
print(f'I learned that flight delays can be predicted based of flight length, but that more types of data (columns) should be analyzed to see if the accuracy of the model can be improved.')
print()